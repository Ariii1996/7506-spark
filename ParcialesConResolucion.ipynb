{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016-01 Recuperatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una red social almacena el contenido de los chats entre sus usuarios\n",
    "en un RDD que tiene registros con el siguiente formato: (chat_id,\n",
    "user_id, nickname, text). Queremos saber cuál es el usuario (user_id)\n",
    "que mas preguntas hace en sus chats, contabilizamos una pregunta por\n",
    "cada caracter “?” que aparezca en el campo text. Programar en Spark\n",
    "un programa que identifique al usuario preguntón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = [\n",
    "    (1, 1, 'damu', 'Qué es esto?'),\n",
    "    (2, 2, 'martin', 'Un chat!???'),\n",
    "    (3, 1, 'damu', 'Ahhh! Y de donde salio? Whatsapp?'),\n",
    "    (4, 2, 'martin', 'Sí! Cómo sabias????'),\n",
    "    (5, 1, 'damu', 'Adivine'),\n",
    "    (6, 3, 'luis', 'Hola!')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(chats);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 'damu', 'Qu\\xc3\\xa9 es esto?'),\n",
       " (2, 2, 'martin', 'Un chat!???'),\n",
       " (3, 1, 'damu', 'Ahhh! Y de donde salio? Whatsapp?'),\n",
       " (4, 2, 'martin', 'S\\xc3\\xad! C\\xc3\\xb3mo sabias????'),\n",
       " (5, 1, 'damu', 'Adivine'),\n",
       " (6, 3, 'luis', 'Hola!')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda x: (x[1], x[3].count('?')))\\\n",
    "    .reduceByKey(lambda x,y: x+y)\\\n",
    "    .reduce(lambda x,y: x if x[1]>y[1] else y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016-01 Parcial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UBER almacena en un cluster todos los datos sobre el movimiento y\n",
    "viajes de todos sus vehículos. Existe un proceso que nos devuelve un\n",
    "RDD llamado trip_summary con los siguientes campos: (driver_id,\n",
    "car_id, trip_id, customer_id, date (YYYYMMDD), distance_traveled),\n",
    "Programar usando Py Spark un programa que nos indique cual fue el\n",
    "conductor con mayor promedio de distancia recorrida por viaje para\n",
    "Abril de 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = [\n",
    "    (1, 1, 1, 1, '20160101', 10),\n",
    "    (2, 2, 2, 2, '20160202', 20),\n",
    "    (1, 1, 3, 1, '20160402', 15),\n",
    "    (1, 1, 4, 3, '20160405', 20),\n",
    "    (2, 2, 5, 4, '20160410', 25),\n",
    "    (3, 3, 6, 3, '20160415', 15),\n",
    "    (2, 2, 7, 1, '20160420', 40),\n",
    "    (3, 3, 8, 2, '20160505', 80)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(trips);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 1, 1, '20160101', 10),\n",
       " (2, 2, 2, 2, '20160202', 20),\n",
       " (1, 1, 3, 1, '20160402', 15),\n",
       " (1, 1, 4, 3, '20160405', 20),\n",
       " (2, 2, 5, 4, '20160410', 25),\n",
       " (3, 3, 6, 3, '20160415', 15),\n",
       " (2, 2, 7, 1, '20160420', 40),\n",
       " (3, 3, 8, 2, '20160505', 80)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, (2, 65))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(lambda x: x[4] > '20160400' and x[4] < '20160500')\\\n",
    "    .map(lambda x: (x[0], (1, x[5])))\\\n",
    "    .reduceByKey(lambda x,y: (x[0]+y[0],x[1]+y[1]))\\\n",
    "    .reduce(lambda x,y: x if float(x[1][1])/x[1][0] > float(y[1][1])/y[1][0] else y)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015-02 2do Recuperatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un telescopio registra automaticamente la luminosidad de distintas\n",
    "estrellas generando un RDD con registros de tipo (star_id,\n",
    "magnitude,spectral_type, timestamp). Queremos obtener un listado de\n",
    "estrellas que tienen el mismo tipo espectral e igual promedio de\n",
    "magnitud una vez redondeado el mismo a un decimal. El resultado\n",
    "debe ser una lista en donde cada elemento de la lista es una lista de ids\n",
    "de estrellas similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = [\n",
    "    (1, 5, 1, 1),\n",
    "    (2, 10, 1, 1),\n",
    "    (3, 6, 1, 1),\n",
    "    (4, 5.5, 2, 1),\n",
    "    (1, 6, 1, 2),\n",
    "    (2, 9, 1, 2),\n",
    "    (3, 5, 1, 2),\n",
    "    (1, 5.5, 1, 3),\n",
    "    (2, 11, 1, 3),\n",
    "    (3, 5.5, 1, 3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(stars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 5, 1, 1),\n",
       " (2, 10, 1, 1),\n",
       " (3, 6, 1, 1),\n",
       " (4, 5.5, 2, 1),\n",
       " (1, 6, 1, 2),\n",
       " (2, 9, 1, 2),\n",
       " (3, 5, 1, 2),\n",
       " (1, 5.5, 1, 3),\n",
       " (2, 11, 1, 3),\n",
       " (3, 5.5, 1, 3)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda x: (x[0], (x[1], x[2], 1)))\\\n",
    "    .reduceByKey(lambda x,y: (x[0]+y[0],x[1],x[2]+y[2]))\\\n",
    "    .map(lambda x: ((x[1][1],round(float(x[1][0])/x[1][2],1)),x[0]))\\\n",
    "    .groupByKey()\\\n",
    "    .filter(lambda x: len(x[1]) > 1)\\\n",
    "    .map(lambda x: (list(x[1])))\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2016-02 Parcial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio queremos programar un sistema que recomiende textos a usuarios en base a sus gustos sobre ciertos términos (palabras).\n",
    "\n",
    "Se cuenta con un RDD de textos de la forma (docId, texto) donde texto es un string de longitud variable.\n",
    "\n",
    "Además contamos con un RDD que indica qué términos le gustan o no a cada usuario de la forma (userId, término, score) por ejemplo (23, “calesita”, -2).\n",
    "\n",
    "Se pide programar en Spark un programa que calcule el score total de cada documento para cada usuario generando un RDD de la forma (userId, docId, score) en donde el score es simplemente la suma de los scores del usuario para los términos que aparecen en el documento.\n",
    "\n",
    "Puede haber términos en los documentos para los cuales no exista score de algunos usuarios, en estos casos simplemente los consideramos neutros (score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    (1, 'pablo honey'),\n",
    "    (2, 'the bends'),\n",
    "    (3, 'ok computer'),\n",
    "    (4, 'kid a'),\n",
    "    (5, 'amnesiac'),\n",
    "    (6, 'hail to the thief'),\n",
    "    (7, 'in rainbows'),\n",
    "    (8, 'the king of limbs'),\n",
    "    (9, 'a moon shaped pool')\n",
    "]\n",
    "\n",
    "scores = [\n",
    "    ('thom', 'pablo', 1),\n",
    "    ('thom', 'honey', 1),\n",
    "    ('martin', 'pablo', -1),\n",
    "    ('martin', 'honey', -1),\n",
    "    ('martin', 'ok', 30),\n",
    "    ('martin', 'computer', 30)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentsRDD = sc.parallelize(documents)\n",
    "scoresRDD = sc.parallelize(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pablo', 1),\n",
       " ('honey', 1),\n",
       " ('the', 2),\n",
       " ('bends', 2),\n",
       " ('ok', 3),\n",
       " ('computer', 3),\n",
       " ('kid', 4),\n",
       " ('a', 4),\n",
       " ('amnesiac', 5),\n",
       " ('hail', 6),\n",
       " ('to', 6),\n",
       " ('the', 6),\n",
       " ('thief', 6),\n",
       " ('in', 7),\n",
       " ('rainbows', 7),\n",
       " ('the', 8),\n",
       " ('king', 8),\n",
       " ('of', 8),\n",
       " ('limbs', 8),\n",
       " ('a', 9),\n",
       " ('moon', 9),\n",
       " ('shaped', 9),\n",
       " ('pool', 9)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = documentsRDD.flatMap(lambda x: [(word, x[0]) for word in x[1].split()])\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinWordsScores = scoresRDD.map(lambda x: (x[1],(x[0],x[2])))\\\n",
    "                .join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('honey', (('thom', 1), 1)),\n",
       " ('honey', (('martin', -1), 1)),\n",
       " ('ok', (('martin', 30), 3)),\n",
       " ('pablo', (('thom', 1), 1)),\n",
       " ('pablo', (('martin', -1), 1)),\n",
       " ('computer', (('martin', 30), 3))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinWordsScores.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('martin', 3), 60), (('thom', 1), 2), (('martin', 1), -2)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinWordsScores.map(lambda x: ((x[1][0][0],x[1][1]),x[1][0][1]))\\\n",
    "               .reduceByKey(lambda x,y: x+y)\\\n",
    "               .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017-01 Parcial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene información estadística de la temporada regular de todos los jugadores de la NBA en un RDD de tuplas con el siguiente formato: (id_jugador, nombre, promedio_puntos, promedio_asistencias, promedio_robos, promedio_bloqueos, promedio_rebotes, promedio_faltas).\n",
    "\n",
    "Un analista de la cadena ESPN está trabajando con un RDD que corresponde a la primera ronda de playoffs y que tiene el siguiente formato: (id_jugador, id_partido, timestamp, cantidad_puntos, cantidad_rebotes, cantidad_bloqueos, cantidad_robos, cantidad_asistencias, cantidad_faltas).\n",
    "\n",
    "En base a estos RDDs se quiere programar en PySpark un programa que genere un RDD con los nombres (sin duplicados) de los jugadores que lograron en algún partido de playoffs una cantidad de asistencias mayor a su promedio histórico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usamos para simplificar el formato, que puede obtenerse con un map.\n",
    "# (id_jugador, nombre, promedio_asistencias)\n",
    "players_all_time_stats = [\n",
    "    (1, 'Manu Ginobili', 800),\n",
    "    (2, 'Kobe Bryant', 100),\n",
    "    (3, 'Marc Gasol', 25),\n",
    "    (4, 'James Harden', 1000)]\n",
    "\n",
    "# usamos para simplificar el formato, que puede obtenerse con un map.\n",
    "# (id_jugador, id_partido, timestamp, cantidad_asistencias)\n",
    "scores = [\n",
    "  (1, 1, 1, 100),\n",
    "  (1, 1, 3, 100),\n",
    "  (2, 1, 1, 150),\n",
    "  (2, 1, 3, 150),\n",
    "  (3, 2, 2, 50),\n",
    "  (3, 2, 3, 50),      \n",
    "  (1, 2, 1, 150),\n",
    "  (1, 2, 3, 150),\n",
    "]\n",
    "\n",
    "players_all_time_stats_rdd = sc.parallelize(players_all_time_stats)\n",
    "scores_rdd = sc.parallelize(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 1), 200), ((1, 2), 300), ((3, 2), 100), ((2, 1), 300)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cambio de clave a id_jugador, partido\n",
    "scores_by_match = scores_rdd.map(lambda a: ((a[0],a[1]),a[3]))\n",
    "scores_by_match = scores_by_match.reduceByKey(lambda a,b: a+b)\n",
    "scores_by_match.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 200), (1, 300), (3, 100), (2, 300)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cambio de clave a id_jugador\n",
    "scores_by_player = scores_by_match.map(lambda a: (a[0][0], a[1]))\n",
    "scores_by_player.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (1, 'Manu Ginobili', 800)),\n",
       " (2, (2, 'Kobe Bryant', 100)),\n",
       " (3, (3, 'Marc Gasol', 25)),\n",
       " (4, (4, 'James Harden', 1000))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# juntamos los datos para poder evaluar lo pedido\n",
    "# preparamos la key del lado de informacion historica de jugadores.\n",
    "\n",
    "all_time_with_key = players_all_time_stats_rdd.map(lambda a: (a[0],a))\n",
    "all_time_with_key.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (200, (1, 'Manu Ginobili', 800))),\n",
       " (1, (300, (1, 'Manu Ginobili', 800))),\n",
       " (2, (300, (2, 'Kobe Bryant', 100))),\n",
       " (3, (100, (3, 'Marc Gasol', 25)))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_by_player = scores_by_player.join(all_time_with_key)\n",
    "scores_by_player.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, (300, (2, 'Kobe Bryant', 100))), (3, (100, (3, 'Marc Gasol', 25)))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overperformers = scores_by_player.filter(lambda a: a[1][0] > a[1][1][2])\n",
    "overperformers.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kobe Bryant', 'Marc Gasol']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veamos los duplicados\n",
    "overperformers = overperformers.map(lambda a: a[1][1][1]).distinct()\n",
    "overperformers.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
